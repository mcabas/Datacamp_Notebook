######################################################################
######################################################################
######################################################################

# COURSE 015_Introduction to Data in R

######################################################################
######################################################################
######################################################################

######## Language of data (Module 01-015)
######################################################################

Introduction to Data in R machete

VIDEO INTRO

 # Load package 
library(openintro) 
# Load data 
data(hsb2)

str(hsb2)

# Load package 
library(dplyr) 
# View the structure of your data
glimpse(hsb2) 

#---------------------------------------------------------------------

Loading data into R

In the previous video, we saw how to load the hsb2 dataset into R using the data() function and how to preview its contents with str().

In this exercise, we'll practice on another dataset, email50, which contains a subset of incoming emails for the first three months of 2012 for a single email account. We'll examine the structure of this dataset and determine the number of rows (observations) and columns (variables).

# Load data
data(email50)

# View the structure of the data
str(email50)

#---------------------------------------------------------------------

VIDEO

Introduction to Data in R machete

 # Load package 
library(openintro) 
# Load data 
data(hsb2)

str(hsb2)

# Load package 
library(dplyr) 
# View the structure of your data
glimpse(hsb2) 

#-----------------------------------------------------------------

Types of variables 
-Numerical (quantitative): numerical values 
	-Continuous: in???nite number of values within a given range, o!en measured 
	-Discrete: speci???c set of numeric values that can be counted or enumerated, o!en counted

-Categorical (qualitative): limited number of distinct categories 
	-Ordinal: ???nite number of values within a given range, ofen measured

#---------------------------------------------------------------------

Identify variable types

Recall from the video that the glimpse() function from dplyr provides a handy alternative to str() for previewing a dataset. In addition to the number of observations and variables, it shows the name and type of each column, along with a neatly printed preview of its values.

Let's have another look at the email50 data, so we can practice identifying variable types.

# Glimpse email50
glimpse(email50)

#---------------------------------------------------------------------

Filtering based on a factor

Categorical data are often stored as factors in R. In this exercise, we'll practice working with a factor variable, number, from the email50 dataset. This variable tells us what type of number (none, small, or big) an email contains.

Recall from the video that the filter() function from dplyr can be used to filter a dataset to create a subset containing only certain levels of a variable. For example, the following code filters the mtcars dataset for cars containing 6 cylinders:

mtcars %>%
  filter(cyl == 6)

# Subset of emails with big numbers: email50_big
email50_big <- email50 %>%
  filter(number == "big")

# Glimpse the subset
glimpse(email50_big)

#---------------------------------------------------------------------

Complete filtering based on a factor

The droplevels() function removes unused levels of factor variables from our dataset. As we saw in the video, it's often useful to determine which levels are unused (i.e. contain zero values) with the table() function.

In this exercise, we'll see which levels of the number variable are dropped after applying the droplevels() function.

# Subset of emails with big numbers: email50_big
email50_big <- email50 %>%
  filter(number == "big")

# Table of the number variable
table(email50_big$number)

# Drop levels
email50_big$number_dropped <- droplevels(email50_big$number)

# Table of the number_dropped variable
table(email50_big$number_dropped)

#---------------------------------------------------------------------

Discretize a variable

 # Calculate average reading score and show the value 
mean(hsb2$read) 
[1] 52.23 

# Calculate average reading score and store as avg_read 
avg_read <- mean(hsb2$read) 

# Do both 
(avg_read <- mean(hsb2$read)) 
[1] 52.23

#New variable: read_cat
hsb2 <- hsb2 %>%
	mutate(read_cat = ifelse(read < avg_read, 
		"below average", "at or above average")) 
logical test 	if TRUE 		if FALSE

#---------------------------------------------------------------------

Discretize a different variable

In this exercise, we'll create a categorical version of the num_char variable in the email50 dataset. num_char is the number of characters in an email, in thousands. This new variable will have two levels ("below median" and "at or above median") depending on whether an email has less than the median number of characters or equal to or more than that value.

The median marks the 50th percentile, or midpoint, of a distribution, so half of the emails should fall in one category and the other half in the other. You will learn more about the median and other measures of center in the next course in this series.

# Calculate median number of characters: med_num_char
(med_num_char <- median(email50$num_char))

# Create num_char_cat variable in email50
email50_fortified <- email50 %>%
  mutate(num_char_cat = ifelse(num_char < med_num_char, "below median", "at or above median"))
  
# Count emails in each category
email50_fortified %>%
  count(num_char_cat)

#---------------------------------------------------------------------

Combining levels of a different factor

Another common way of creating a new variable based on an existing one is by combining levels of a categorical variable. For example, the email50 dataset has a categorical variable called number with levels "none", "small", and "big", but suppose we're only interested in whether an email contains a number. In this exercise, we will create a variable containing this information and also visualize it.

For now, do your best to understand the code we've provided to generate the plot. We will go through it in detail in the next video.

# Create number_yn column in email50
email50_fortified <- email50 %>%
  mutate(
    number_yn = case_when(
      # if number is "none", make number_yn "no"
      number == "none" ~ "no", 
      # if number is not "none", make number_yn "yes"
      number != "none" ~ "yes"  
    )
  )
  

# Visualize the distribution of number_yn
ggplot(email50_fortified, aes(x = number_yn)) +
  geom_bar()

#---------------------------------------------------------------------

Visualizing numerical and categorical data

In this exercise, we'll visualize the relationship between two numerical variables from the email50 dataset, conditioned on whether or not the email was spam. This means that we will use an aspect of the plot (like color or shape) to identify the levels in the spam variable so that we can compare plotted values between them.

Recall that in the ggplot() function, the first argument is the dataset, then we map the aesthetic features of the plot to variables in the dataset, and finally the geom_*() layer informs how data are represented on the plot. In this exercise, we will make a scatterplot by adding a geom_point() layer to the ggplot() call.

# Load ggplot2
library(ggplot2)

# Scatterplot of exclaim_mess vs. num_char
ggplot(email50, aes(x = num_char, y = exclaim_mess, color = factor(spam))) +
  geom_point()


######################################################################
######################################################################
######################################################################

######## Study types and cautionary tales  (Module 02-015)
######################################################################

Types of studies 
??? Observational study: 
	??? Collect data in a way that does not directly interfere with how the data arise 
	??? Only correlation can be inferred 

??? Experiment: 
	??? Randomly assign subjects to various treatments 
	??? Causation can be inferred

#---------------------------------------------------------------------

Identify type of study: Reading speed and font

A study is designed to evaluate whether people read text faster in Arial or Helvetica font. A group of volunteers who agreed to be a part of the study are randomly assigned to two groups: one where they read some text in Arial, and another where they read the same text in Helvetica. At the end, average reading speeds from the two groups are compared.

What type of study is this?

Awesome! Even though participants are volunteers, this is still an experiment!

#---------------------------------------------------------------------

Identify type of study: Countries

Next, let's take a look at data from a different study on country characteristics. First, load the data and view it, then identify the type of study. Remember, an experiment requires random assignment.

# Load data
data(gapminder)

# Glimpse data
glimpse(gapminder)

# Identify type of study: observational or experimental
type_of_study <- "observational"

#---------------------------------------------------------------------

Random. 
??? Random sampling: 
	??? At selection of subjects from population 
	??? Helps generalizability of results 
??? Random assignment: 
	??? At selection of subjects from population 
	??? Helps infer causation from results

#---------------------------------------------------------------------

Random sampling or random assignment?

One of the early studies linking smoking and lung cancer compared patients who are already hospitalized with lung cancer to similar patients without lung cancer (hospitalized for other reasons), and recorded whether each patient smoked. Then, proportions of smokers for patients with and without lung cancer were compared.

Does this study employ random sampling and/or random assignment?

Right! Random assignment is not employed because the conditions are not imposed on the patients by the people conducting the study; random sampling is not employed because the study records the patients who are already hospitalized, so it wouldn't be appropriate to apply the findings back to the population as a whole.

#---------------------------------------------------------------------

Identify the scope of inference of study

Volunteers were recruited to participate in a study where they were asked to type 40 bits of trivia-for example, "an ostrich's eye is bigger than its brain"-into a computer. A randomly selected half of these subjects were told the information would be saved in the computer; the other half were told the items they typed would be erased.

Then, the subjects were asked to remember these bits of trivia, and the number of bits of trivia each subject could correctly recall were recorded. It was found that the subjects were significantly more likely to remember information if they thought they would not be able to find it later.

The results of the study ___ be generalized to all people and a causal link between believing information is stored and memory ___ be inferred based on these results.

Correct! There is no random sampling since the subjects of the study were volunteers, so the results cannot be generalized to all people. However, due to random assignment, we are able to infer a causal link between the belief information is stored and the ability to recall that same information.

#---------------------------------------------------------------------

Simpson's paradox

#---------------------------------------------------------------------

Number of males and females admitted

The goal of this exercise is to determine the numbers of male and female applicants who got admitted and rejected. Specifically, we want to find out how many males are admitted and how many are rejected. And similarly we want to find how many females are admitted and how many are rejected.

To do so we will use the count() function from the dplyr package.

In one step, count() groups the data and then tallies the number of observations in each level of the grouping variable. These counts are available under a new variable called n.

# Load packages
library(dplyr)

# Count number of male and female applicants admitted
ucb_admit %>%
  count(Gender, Admit)

#---------------------------------------------------------------------

Proportion of males admitted overall

Next we'll calculate the percentage of males and percentage of females admitted, by creating a new variable, called prop (short for proportion) based off of the counts calculated in the previous exercise and using the mutate() from the dplyr package.

Proportions for each row of the data frame we created in the previous exercise can be calculated as n / sum(n). Note that since the data are grouped by gender, sum(n) will be calculated for males and females separately.

ucb_admission_counts %>%
  # Group by gender
  group_by(Gender) %>%
  # Create new variable
  mutate(prop = n / sum(n)) %>%
  # Filter for admitted
  filter(Admit == "Admitted")

#---------------------------------------------------------------------

Proportion of males admitted for each department

Finally we'll make a table similar to the one we constructed earlier, except we'll first group the data by department. The goal is to compare the proportions of male admitted students across departments.

Proportions for each row of the data frame we create can be calculated as n / sum(n). Note that since the data are grouped by department and gender, sum(n) will be calculated for males and females separately for each department.

STEP 01

ucb_admission_counts <- ucb_admit %>%
  # Counts by department, then gender, then admission status
  count(Dept, Gender, Admit)

# See the result
ucb_admission_counts

STEP 02

ucb_admission_counts  %>%
  # Group by department, then gender
  group_by(Dept, Gender) %>%
  # Create new variable
  mutate(prop = n / sum(n)) %>%
  # Filter for male and admitted
  filter(Gender == "Male", Admit == "Admitted")

#---------------------------------------------------------------------

Admission rates for males across departments

The final result from the previous exercise is available in your workspace as perc_admit_by_dept. Which of the following best describes the relationship between admission status and gender?

females are more like to be admitted in most departments

#---------------------------------------------------------------------

Identify type of study: Countries [new]

Next, let's take a look at data from a different study on country characteristics. The data come from the gapminder R package. To view the top 10 rows of the data, simply type gapminder in the console. You are welcomed to view the data using other functionality we have learned so far as well.

Then, identify the type of study this data come from.

######################################################################
######################################################################
######################################################################

########  Sampling strategies and experimental design  (Module 03-015)
######################################################################

Ver diapos... 

#---------------------------------------------------------------------

Simple random sample in R

Suppose we want to collect some data from a sample of eight states. A list of all states and the region they belong to (Northeast, Midwest, South, West) are given in the us_regions data frame.

# Simple random sample: states_srs
states_srs <- us_regions %>%
  sample_n(size = 8)

# Count states by region
states_srs %>%
  count(region)

#---------------------------------------------------------------------

Stratified sample in R

In the previous exercise, we took a simple random sample of eight states. However, we did not have any control over how many states from each region got sampled. The goal of stratified sampling in this context is to have control over the number of states sampled from each region. Our goal for this exercise is to sample an equal number of states from each region.

# Stratified sample
states_str <- us_regions %>%
  group_by(region) %>%
  sample_n(size = 2)

# Count states by region
states_str %>%
  count(region)

#---------------------------------------------------------------------

Principles of  experimental design

Principles of experimental design 
??? Control: compare treatment of interest to a control group 
??? Randomize: randomly assign subjects to treatments 
??? Replicate: collect a su???ciently large sample within a study, or replicate the entire study 
??? Block: account for the potential e???ect of confounding variables 
	??? Group subjects into blocks based on these variables 
	??? Randomize within each block to treatment groups


######################################################################
######################################################################
######################################################################

######## Case study  (Module 04-015)
######################################################################

Inspect the data

The purpose of this chapter is to give you an opportunity to apply and practice what you've learned on a real world dataset. For this reason, we'll provide a little less guidance than usual.

The data from the study described in the video are available in your workspace as evals. Let's take a look!

# Inspect evals
glimpse(evals)

#---------------------------------------------------------------------

Identify variable types

It's always useful to start your exploration of a dataset by identifying variable types. The results from this exercise will help you design appropriate visualizations and calculate useful summary statistics later in your analysis.

# Inspect variable types
glimpse(evals)

# Remove non-factor variables from the vector below
cat_vars <- c("rank", "ethnicity", "gender", "language",
              "cls_level", "cls_profs", "cls_credits",
              "pic_outfit", "pic_color")

#---------------------------------------------------------------------

Recode a variable

The cls_students variable in evals tells you the number of students in the class. Suppose instead of the exact number of students, you're interested in whether the class is

    "small" (18 students or fewer),
    "midsize" (19 - 59 students), or
    "large" (60 students or more).

# Recode cls_students as cls_type
evals_fortified <- evals %>%
  mutate(
    cls_type = case_when(
      cls_students <= 18                         ~ "small",
      c(cls_students >= 19 & cls_students <= 59) ~ "midsize",
      cls_students >= 60                         ~ "large"
    )
  )
  
  Excellent! The cls_type variable is a categorical variable, stored as a character vector. You could have made it a factor variable by wrapping the nested ifelse() statements inside factor(). You don't have to do that now. Let's move on! 

#---------------------------------------------------------------------

Create a scatterplot

The bty_avg variable shows the average beauty rating of the professor by the six students who were asked to rate the attractiveness of these faculty. The score variable shows the average professor evaluation score, with 1 being very unsatisfactory and 5 being excellent.

# Scatterplot of score vs. bty_avg
ggplot(evals, aes(x = bty_avg, y = score)) +
  geom_point()

#---------------------------------------------------------------------

Create a scatterplot, with an added layer

Suppose you are interested in evaluating how the relationship between a professor's attractiveness and their evaluation score varies across different class types (small, midsize, and large).

# Scatterplot of score vs. bty_avg colored by cls_type
ggplot(evals, aes(x = bty_avg, y = score, color = cls_type)) +
  geom_point()

END